{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.077/IDS.147 Problem Set 5 <br>\n",
    "**Name:** Chun-Hei Lam. **ID:** 928931321 <br>\n",
    "**Declaration:** I pledge that the work submitted for this coursework is my own unassisted work unless stated otherwise. <br>\n",
    "**Acknowledgement to:** Harry Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "misclass_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "def sign_loss(y_true, y_pred):\n",
    "    diff = 1-np.sum(np.abs(np.heaviside(y_true,0) - np.heaviside(y_pred,0)))/len(y_true)\n",
    "    return diff\n",
    "\n",
    "misclass_sign_scorer = make_scorer(sign_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTF 2.8 Handwriting Data\n",
    "Compare the classification performance of linear regression and k–nearest neighbor classification on the `zipcode` data. **In particular, consider only the $2$’s and $3$’s, and $k = 1, 3, 5, 7$ and $15$.** Show both the training and test error for each choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution: First preprocess the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"zip.train.gz\", delim_whitespace=True, header=None)\n",
    "train = train[(train[0] == 2) | (train[0] == 3)].sort_values(by=0)\n",
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train[0].copy()\n",
    "y_train[y_train == 2] = -1\n",
    "y_train[y_train == 3] = 1\n",
    "\n",
    "test = pd.read_csv(\"zip.test.gz\", delim_whitespace=True, header=None)\n",
    "test = test[(test[0] == 2) | (test[0] == 3)].sort_values(by=0)\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test[0].copy()\n",
    "y_test[y_test == 2] = -1\n",
    "y_test[y_test == 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Performance of linear classifier.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.994240460763139, test score = 0.9587912087912088\n"
     ]
    }
   ],
   "source": [
    "linear_clf = sklearn.linear_model.RidgeClassifier(alpha=0).fit(X_train, y_train) #ridge with alpha = 0 is OLS\n",
    "train_score = linear_clf.score(X_train, y_train)\n",
    "test_score = linear_clf.score(X_test, y_test)\n",
    "print(f\"train score = {train_score}, test score = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Performance of kNN classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, train score = 1.0, test score = 0.9752747252747253\n",
      "k = 3, train score = 0.9949604031677466, test score = 0.9697802197802198\n",
      "k = 5, train score = 0.994240460763139, test score = 0.9697802197802198\n",
      "k = 7, train score = 0.9935205183585313, test score = 0.967032967032967\n",
      "k = 15, train score = 0.9906407487401008, test score = 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "for k in (1,3,5,7,15):\n",
    "    kNN_clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train)\n",
    "    train_score = kNN_clf.score(X_train, y_train)\n",
    "    test_score = kNN_clf.score(X_test, y_test)\n",
    "    print(f\"k = {k}, train score = {train_score}, test score = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTF 7.5 Linear Smoother\n",
    "For a linear smoother $\\hat{\\vec{y}} = S\\vec{y}$, show that\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^N \\text{Cov}(\\hat{y}_i, y_i) = \\text{tr}(S) \\sigma^2_\\epsilon\n",
    "\\end{equation}\n",
    "which justifies its use as the effective number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution: Just note that*\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^N \\text{Cov}(\\hat{y}_i, y_i) = \\sum_{i=1}^N [\\text{Cov}(S\\vec{y}, \\vec{y})]_{ii} = \\sum_{i=1}^N [S\\text{Cov}(\\vec{y}, \\vec{y})]_{ii} = \\sum_{i=1}^N [S \\sigma^2_\\epsilon I]_{ii} = \\text{tr}(S) \\sigma^2_\\epsilon\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTF 3.17 Spam Data\n",
    "Estimated coefficients and test error results, for different subset and shrinkage methods applied to the `spam.txt` data. The blank entries correspond to variables omitted. **Best subset regression is NOT required.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution: Preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.txt\", delim_whitespace=True, header=None)\n",
    "X = df.iloc[:,:57].copy()\n",
    "y = df.iloc[:,57].copy()\n",
    "y[y==0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For each classifier return the coefficients and test errors for 10 folds CV.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score = 0.8500792228614543 +/- 0.11245239140272323\n"
     ]
    }
   ],
   "source": [
    "# OLS\n",
    "np.random.seed(seed)\n",
    "ols_clf = sklearn.linear_model.LinearRegression()\n",
    "ols_scores = cross_val_score(ols_clf, X, y, cv=10, scoring=misclass_sign_scorer)\n",
    "print(f\"test score = {ols_scores.mean()} +/- {ols_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score = 0.8826360464019617 +/- 0.01871343616407231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87418655, 0.8826087 , 0.85869565, 0.90217391, 0.88043478,\n",
       "       0.89782609, 0.91956522, 0.88695652, 0.86086957, 0.86304348])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge\n",
    "np.random.seed(seed)\n",
    "ridge_clf = sklearn.linear_model.RidgeClassifierCV(alphas=np.logspace(-3,3,num=7))\n",
    "ridge_scores = cross_val_score(ridge_clf, X, y, cv=10, scoring=misclass_scorer)\n",
    "print(f\"test score = {ridge_scores.mean()} +/- {ridge_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphas': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       " 'fit_intercept': True,\n",
       " 'normalize': False,\n",
       " 'scoring': None,\n",
       " 'cv': None,\n",
       " 'gcv_mode': None,\n",
       " 'store_cv_values': False,\n",
       " 'alpha_per_target': False,\n",
       " 'class_weight': None,\n",
       " 'n_features_in_': 57,\n",
       " '_label_binarizer': LabelBinarizer(neg_label=-1),\n",
       " 'alpha_': 10.0,\n",
       " 'best_score_': -0.4480910418567984,\n",
       " 'coef_': array([[-9.49604285e-02, -2.39306061e-02,  7.77636486e-02,\n",
       "          2.39186620e-02,  1.68352912e-01,  2.33021201e-01,\n",
       "          4.21380837e-01,  1.86650644e-01,  1.41900693e-01,\n",
       "          3.04785798e-02,  1.09452907e-01, -5.55903562e-02,\n",
       "          2.65804799e-02,  8.97933359e-03,  4.11109140e-02,\n",
       "          1.50486260e-01,  1.04641832e-01,  1.10113486e-01,\n",
       "          2.86645551e-02,  1.23364833e-01,  1.06064623e-01,\n",
       "          8.82548004e-02,  3.46682305e-01,  1.80143926e-01,\n",
       "         -4.66129486e-02, -4.40852596e-02, -2.44000986e-02,\n",
       "          6.89156145e-03, -1.42308353e-02, -1.00385830e-01,\n",
       "         -4.35787313e-02,  4.76656254e-02, -8.41956162e-02,\n",
       "          6.32175423e-02, -6.18977398e-02,  5.17598441e-02,\n",
       "         -6.68798973e-02, -1.02061585e-01, -4.05493038e-02,\n",
       "          7.86797360e-02, -1.77739732e-02, -7.43702191e-02,\n",
       "         -1.23018445e-01, -6.46649918e-02, -7.05868305e-02,\n",
       "         -7.56439569e-02, -2.84782987e-01, -1.13654154e-01,\n",
       "         -2.68459881e-01, -1.15169557e-01, -9.98505509e-02,\n",
       "          1.36538161e-01,  4.50621147e-01,  5.49270801e-02,\n",
       "          4.80748033e-04,  1.32756398e-04,  1.61071778e-04]]),\n",
       " 'intercept_': array([-0.60038609])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.fit(X,y).__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score = 0.8476898047722343 +/- 0.1151004063745352\n"
     ]
    }
   ],
   "source": [
    "# LASSO\n",
    "np.random.seed(seed)\n",
    "lasso_clf = sklearn.linear_model.LassoCV(alphas=np.logspace(-3,3,num=7))\n",
    "lasso_scores = cross_val_score(lasso_clf, X, y, cv=10, scoring=misclass_sign_scorer)\n",
    "print(f\"test score = {lasso_scores.mean()} +/- {lasso_scores.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTF 3.30 Elastic Net and Lasso\n",
    "Consider the elastic-net optimization problem:\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_\\beta \\left( \\|\\vec{y} - X\\vec{\\beta} \\|^2 + \\lambda \\left( \\alpha \\| \\beta \\|_2^2 + (1-\\alpha) \\|\\beta\\|_1 \\right)\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Show how one can turn this into a lasso problem, using an augmented version of $X$ and $\\vec{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution: Let $\\tilde{X} = \\begin{pmatrix} X \\\\ \\sqrt{\\lambda \\alpha} I \\end{pmatrix}$ and $\\tilde{Y} = \\begin{pmatrix} \\vec{y} \\\\ \\vec{0} \\end{pmatrix}$. Then we have \n",
    "\\begin{equation}\n",
    "\\|\\tilde{y} - \\tilde{X}\\vec{\\beta} \\|^2_2 + \\lambda (1-\\alpha) \\|\\beta\\|_1 = \\| \\vec{y} - X\\vec{\\beta} \\|^2_2 + (\\sqrt{\\alpha \\lambda})^2 \\|\\vec{\\beta} \\|^2_2 + \\lambda (1-\\alpha) \\|\\beta\\|_1\n",
    "\\end{equation}*\n",
    "We have thus reduce an elastic net problem to a LASSO problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
