{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.077/IDS.147 Problem Set 7 <br>\n",
    "**Name:** Chun-Hei Lam. **ID:** 928931321 <br>\n",
    "**Declaration:** I pledge that the work submitted for this coursework is my own unassisted work unless stated otherwise. <br>\n",
    "**Acknowledgement to:** Harry Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Data\n",
    "\n",
    "Fit a SVM and Neural Netmodel to the spamdata and compare the classification results to the treemodel given in Section 9.2.5 for the spam data. For example, you might look at measures like sensitivity and specificity.Youmight also compare the interpretability of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"spam.txt\", sep = ' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam.iloc[:, :-1]\n",
    "y = spam.iloc[:, [-1]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1111)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state = 2222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(10000, activation=\"sigmoid\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 7.4774 - accuracy: 0.6183\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.8380 - accuracy: 0.6782\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.6787 - accuracy: 0.6830\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.6601\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5960 - accuracy: 0.7010\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.6032 - accuracy: 0.6923\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.8152 - accuracy: 0.6808\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5618 - accuracy: 0.6881\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.7007\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5460 - accuracy: 0.7197\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.7037\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.6821\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5434 - accuracy: 0.7054\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.5767 - accuracy: 0.6906\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5343 - accuracy: 0.7167\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5175 - accuracy: 0.7337\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7212\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7206\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5428 - accuracy: 0.6945\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.6999\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.7000\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5456 - accuracy: 0.7215\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7251\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.6941\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.8375 - accuracy: 0.6797\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5690 - accuracy: 0.7055\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.6976\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.6522 - accuracy: 0.7262\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7167\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.5539 - accuracy: 0.7253\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7174\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5408 - accuracy: 0.7223\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7145\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5583 - accuracy: 0.7079\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5472 - accuracy: 0.7072\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7301\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.7528\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5111 - accuracy: 0.7402\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.6955\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5114 - accuracy: 0.7194\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5161 - accuracy: 0.7052\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.7252\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.7318\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4852 - accuracy: 0.7459\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5516 - accuracy: 0.7031\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5096 - accuracy: 0.7522\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5165 - accuracy: 0.74 - 0s 7ms/step - loss: 0.5181 - accuracy: 0.7424\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5841 - accuracy: 0.7187\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.7377\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.7566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25dbf148d88>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7293\n",
      "0.5424212217330933 0.729347825050354\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pharmaceutical Industry\n",
    "\n",
    "An equities analyst is studying the pharmaceutical industry and would like your help inexploring and understanding the financial data collected by her firm.  Her main objective is to understand the structure of the pharmaceutical industry using some basic financial measures. Financial data gathered on 21 firms in the pharmaceutical industry are available in the file posted on Canvas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9ef2c358be93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpharm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./pharmaceuticals.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'read' is not defined"
     ]
    }
   ],
   "source": [
    "pharm = pd.read_csv(\"./pharmaceuticals.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each firm, the following variables are recorded:\n",
    "\n",
    "1. Market capitalization (in billions of dollars)\n",
    "2. Beta\n",
    "3. Price/earnings ratio \n",
    "4. Return on equity \n",
    "5. Return on assets \n",
    "6. Asset turnover \n",
    "7. Leverage \n",
    "8. Estimated revenue growth \n",
    "9. Net profit margin\n",
    "10. Median recommendation (across major brokerages)\n",
    "11. Location of firm’s headquarters\n",
    "12. Stock exchange on which the firm is listed\n",
    "\n",
    "Use cluster analysis to explore and analyze the given dataset as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (a):** Use only the quantitative variables (1 to 9) to cluster the 21 firms. Justify the various choices made in conducting the cluster analysis, such as weights accorded different variables, the specific clustering algorithm/s used, the numberof clusters formed, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution. As pointed out in recitation, it seems like the Ward's algorithm is the most robust hierachical clustering algorithm, and we are using it here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.cluster.AgglomerativeClustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b):** Interpret the clusterswith respect to the quantitative variables that were used in forming the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward', connectivity=connectivity).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (c):** Is there a pattern in the clusters with respect to the qualitative variables (10 to 12) (those not used in forming the clusters)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (d):** Provide an appropriate name for each cluster using any or all of the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Solution:*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
